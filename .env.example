# ============================================================
# LLM 智能客服系统 - 环境变量配置
# 复制此文件为 .env 并填入实际值
# ============================================================

# ---- 应用基础配置 ----
APP_NAME=LLM智能客服系统
APP_ENV=development          # development | production
APP_HOST=0.0.0.0
APP_PORT=8000
DEBUG=true
SECRET_KEY=your-super-secret-key-change-in-production

# ---- JWT 配置 ----
JWT_SECRET_KEY=your-jwt-secret-key-at-least-32-chars
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=60
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# ---- LLM 配置 ----
# 选择 LLM 提供商: openai | ollama | azure_openai
# 推荐免费方案: 使用 Ollama 在本地运行模型
LLM_PROVIDER=ollama

# ── 方案A: Ollama 本地模型（免费推荐）──────────────────────
# 安装: curl -fsSL https://ollama.com/install.sh | sh
# 拉取模型: ollama pull qwen2.5:7b && ollama pull nomic-embed-text
#
# Docker 环境下访问宿主机 Ollama（docker-compose 已配置 extra_hosts）:
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=qwen2.5:7b
# 嵌入模型固定为 nomic-embed-text（backend/core/llm/client.py 中配置）
#
# 本地直接运行（非 Docker）时改为:
# OLLAMA_BASE_URL=http://localhost:11434

# ── 方案B: OpenAI API ──────────────────────────────────────
# LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_CHAT_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_MAX_TOKENS=2048
OPENAI_TEMPERATURE=0.7

# ── 方案C: Azure OpenAI ────────────────────────────────────
# LLM_PROVIDER=azure_openai
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_DEPLOYMENT_NAME=
AZURE_OPENAI_API_VERSION=2024-02-01

# ---- 数据库配置 ----
# Docker Compose 环境下使用服务名 postgres/redis 作为主机名
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=cs_user
POSTGRES_PASSWORD=your-db-password
POSTGRES_DB=customer_service
DATABASE_URL=postgresql+asyncpg://cs_user:your-db-password@postgres:5432/customer_service
# 本地直接运行时改为 @localhost:5432

# ---- Redis 配置 ----
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_URL=redis://redis:6379/0
# 本地直接运行时改为 redis://localhost:6379/0

# 缓存过期时间（秒）
CACHE_TTL_CONVERSATION=3600    # 对话缓存1小时
CACHE_TTL_KNOWLEDGE=86400      # 知识库缓存1天

# ---- 向量数据库 (ChromaDB) 配置 ----
CHROMA_PERSIST_DIR=./data/chroma_db
CHROMA_COLLECTION_NAME=knowledge_base

# ---- RAG 配置 ----
RAG_TOP_K=5                    # 检索返回的最相关文档数
RAG_SCORE_THRESHOLD=0.5        # 相似度阈值
RAG_CHUNK_SIZE=500             # 文档分块大小 (字符数)
RAG_CHUNK_OVERLAP=50           # 分块重叠大小

# ---- 对话配置 ----
MAX_HISTORY_TURNS=10           # 上下文保留的最大对话轮数
MAX_CONTEXT_TOKENS=4000        # 最大上下文 token 数

# ---- 限流配置 ----
RATE_LIMIT_PER_MINUTE=60       # 每分钟最大请求数
RATE_LIMIT_PER_USER=20         # 每用户每分钟最大请求数

# ---- 日志配置 ----
LOG_LEVEL=INFO                 # DEBUG | INFO | WARNING | ERROR
LOG_FILE=./logs/app.log
LOG_ROTATION=100 MB
LOG_RETENTION=30 days

# ---- CORS 配置 ----
CORS_ORIGINS=["http://localhost:5173","http://localhost:3000","http://localhost:80","http://localhost"]
